{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13752\\4280311024.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtae_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparallel_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morthogonal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines_3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tae_module import *\n",
    "from data.data import parallel_line, orthogonal, triangle, lines_3D\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TensorizedAutoencoder(nn.Module):\n",
    "    def __init__(self, autoencoder, Y_data, n_clusters, regularizer_coef=0.01, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.logging = True\n",
    "        self.device = device\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centers = None\n",
    "        \n",
    "        self.autoencoders = GroupedAE(autoencoder, n_clusters)\n",
    "        self.mse = nn.functional.mse_loss\n",
    "        self.reg = regularizer_coef\n",
    "\n",
    "        self.random_state = None    # set manually if needed, call model._init_clusters(Y) again\n",
    "        self._init_clusters(Y_data)\n",
    "\n",
    "    def _init_clusters(self, Y):\n",
    "        self.centers, _ = kmeans_plusplus(Y.reshape(len(Y), -1).numpy(), n_clusters=self.n_clusters, random_state=self.random_state)\n",
    "        self.centers = torch.from_numpy(self.centers)\n",
    "\n",
    "    def forward_pass(self, x, clust_idx=None, centers=None, return_embed=False):\n",
    "        \"\"\"\n",
    "        Getting output for a given batch of inputs for \n",
    "        1. computed centers and Nearest-Center-Assignment (NCA)\n",
    "        2. input override centers and NCA\n",
    "        3. input override assigned clusters\n",
    "        \"\"\"\n",
    "        if self.centers is None and centers is None:\n",
    "            print(\"Cannot compute output!\") \n",
    "            return\n",
    "\n",
    "        device = x.device\n",
    "        centers = centers if centers is not None else self.centers\n",
    "        centers = centers.to(device).reshape(self.n_clusters,-1)\n",
    "        if clust_idx is None:\n",
    "            clust_idx = self._assign_centers_to_data(x, centers)\n",
    "\n",
    "        embed, out = torch.tensor([]).to(device), torch.tensor([]).to(device)\n",
    "        for idx in range(len(x)):\n",
    "            samp = x[idx:idx+1]     # 1, 3, 32, 32\n",
    "            clust = clust_idx[idx]\n",
    "            e, o = self.autoencoders.AE[clust](samp-centers[clust].reshape(samp.shape), True)\n",
    "            embed = torch.cat((embed, e))\n",
    "            out = torch.cat((out, o))\n",
    "\n",
    "        if return_embed: return embed, out\n",
    "        return out\n",
    "    \n",
    "    def compute_loss(self, x, y, centers, assigned_clusters):\n",
    "        x_ = x.clone()  # [batch, 3, 32, 32]\n",
    "        y_ = y.clone()  # [batch, 3, 32, 32]\n",
    "        \n",
    "        embed, out = self.autoencoders(x_, centers, True)   # [batch, n_clusters, 3, 32, 32]\n",
    "\n",
    "        losses, new_idxs = torch.tensor([]).to(x_.device), torch.tensor([])\n",
    "        for idx in range(len(x_)):\n",
    "            embed_, out_, true_ = embed[idx], out[idx], y_[idx]\n",
    "            # embed_, out_: (n_clusters, 3, 32, 32)\n",
    "\n",
    "            embed_norm = embed_.clone()\n",
    "            while len(embed_norm.shape) > 1:\n",
    "                embed_norm = torch.norm(embed_norm, dim=1)\n",
    "\n",
    "            dims = [i for i in range(1,len(x_.shape[1:])+1)]\n",
    "            mse_proxy = torch.sum((out_ - true_.unsqueeze(0)) ** 2, dim=dims)\n",
    "            loss_proxy = mse_proxy + self.reg * (embed_norm ** 2)\n",
    "\n",
    "            new_idx = loss_proxy.argmin()   #reassigned clust\n",
    "            \n",
    "            clust = assigned_clusters[idx]  \n",
    "            loss = self.mse(out_[clust], true_) + self.reg * (embed_norm[clust] ** 2) #using currently assigned\n",
    "\n",
    "            losses = torch.cat((losses, loss.unsqueeze(0)))\n",
    "            new_idxs = torch.cat((new_idxs, new_idx.unsqueeze(0)))\n",
    "\n",
    "        new_indices = nn.functional.one_hot(new_idxs.long(), self.n_clusters).T\n",
    "        losses = sum(losses)/len(losses)        \n",
    "\n",
    "        return losses, new_indices\n",
    "\n",
    "    def _update_centers(self, Y, clust_assign):\n",
    "        clust_assign.to(Y.device)\n",
    "        new_centers = clust_assign.float() @ Y.reshape(len(Y), -1).float()\n",
    "        new_norm = torch.sum(clust_assign, axis=1, dtype=torch.float).reshape(-1, 1) @ \\\n",
    "                        torch.ones(1, self.centers.shape[1], dtype=torch.float)\n",
    "        new_centers = new_centers / new_norm\n",
    "        return new_centers\n",
    "\n",
    "    def _assign_centers_to_data(self, data, centers=None):\n",
    "        centers = centers if centers is not None else self.centers\n",
    "        centers = centers.reshape(self.n_clusters, -1)\n",
    "        \n",
    "        assignments = torch.tensor([])\n",
    "        for i in range(self.n_clusters):\n",
    "            d = torch.norm(data.reshape(len(data), -1) - self.centers[i], dim=1).reshape(-1,1)\n",
    "            assignments = torch.cat((assignments,d), dim=1)\n",
    "        return assignments.argmin(dim=1)\n",
    "\n",
    "    def train(self, X, Y, Dataset, epochs, lr, batch_size, **dataset_kwargs):\n",
    "        self.configure_optimizers(lr)\n",
    "\n",
    "        device = self.device\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        clust_assign = self._assign_centers_to_data(Y)\n",
    "        clust_assign_onehot = nn.functional.one_hot(clust_assign).T.float()\n",
    "\n",
    "        self.centers = self._update_centers(Y, clust_assign_onehot)\n",
    "\n",
    "        dataset = Dataset(X, Y, **dataset_kwargs)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=False)\n",
    "\n",
    "        pbar = ProgressBar(epochs)\n",
    "        es = EarlyStopping()\n",
    "\n",
    "        losses = []\n",
    "        for epoch in pbar.bar:\n",
    "            \n",
    "            for batch_idx, (x, y) in enumerate(dataloader):\n",
    "                index = batch_idx * batch_size\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                loss, new_indices = self.compute_loss(x, y, self.centers, clust_assign)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                clust_assign_onehot[:,index:index+batch_size] = new_indices\n",
    "                clust_assign = clust_assign_onehot.argmax(0)\n",
    "\n",
    "                new_centers = self._update_centers(Y, clust_assign_onehot) \n",
    "                self.centers = (index * self.centers + batch_size * new_centers) / (index + batch_size)\n",
    "\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            es.update(losses[-1])\n",
    "            pbar.update(epoch, losses[-1], es.es)\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def configure_optimizers(self, lr):\n",
    "        self.optimizer = torch.optim.Adagrad(self.parameters(), lr=lr)\n",
    "\n",
    "device = 'cpu'#'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "X, Y, X_noise, n_clusters = triangle(noise=0.1)\n",
    "\n",
    "ae = Autoencoder(\n",
    "    enc_channels=(5,2), \n",
    "    dec_channels=(2,5),\n",
    "    bias=False\n",
    ")\n",
    "\n",
    "tae = TensorizedAutoencoder(ae, X, n_clusters=3).to(device)\n",
    "\n",
    "dummy_in = torch.randn((64,5)).to(device)\n",
    "dummy_c = torch.randn((3,5)).to(device)\n",
    "dummy_ass = tae._assign_centers_to_data(dummy_in, dummy_c)\n",
    "\n",
    "tae.autoencoders(dummy_in,dummy_c).shape\n",
    "tae.forward_pass(dummy_in, return_embed=False).shape\n",
    "loss, new_indices = tae.compute_loss(dummy_in, dummy_in, tae.centers, dummy_ass)\n",
    "print(loss, new_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DummyDataset(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for n, (x,y) in enumerate(loader):\n",
    "    print((x == X[n]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|███████████████████████████████████| 50/50 [00:14<00:00,  3.39it/s, loss: nan, es: 0]\n"
     ]
    }
   ],
   "source": [
    "from inpainting_utils import DummyDataset\n",
    "\n",
    "losses = tae.train(X.float(), X.float(), DummyDataset, 50, 1e-3, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b017594118ac99b5f427c0ae90fba14825388823942a8c6fc2c353b3b1713eba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
