{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all assests from base.py...\n",
      "Imported modules   : numpy, pandas, matplotlib.pyplot\n",
      "Imported functions : npy, axes_off, get_var_name, shapes, tqdm, plot_history, minmax, values\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data.data import parallel_line, orthogonal, triangle, lines_3D\n",
    "from train_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias, activation=None):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(in_features, out_features, bias)\n",
    "        self.act = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.act is None:\n",
    "            return self.layer(x)\n",
    "        \n",
    "        return self.act(self.layer(x))\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Requires: enc_channels, dec_channels, bias, activations (nn.ReLU(), nn.GELU(), etc)\n",
    "        \"\"\"\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        enc_channels, dec_channels = kwargs['enc_channels'], kwargs['dec_channels']\n",
    "        bias = kwargs['bias']\n",
    "        activations = kwargs['activations']\n",
    "\n",
    "        if enc_channels[-1] != dec_channels[0]: \n",
    "            print(\"[WARN] First shape of dec_channels does not match the terminal channel in enc_channels, proceeding with additional layer...\")\n",
    "            dec_channels = (enc_channels[-1],)+dec_channels\n",
    "\n",
    "        self.enc = nn.Sequential()\n",
    "        for i in range(len(enc_channels)-1):\n",
    "            self.enc.add_module(f'enc_dense{i}', DenseBlock(enc_channels[i], enc_channels[i+1], bias=bias, activation=activations))\n",
    "\n",
    "        self.dec = nn.Sequential()\n",
    "        for i in range(len(dec_channels)-1):\n",
    "            self.dec.add_module(f'dec_dense{i}', DenseBlock(dec_channels[i], dec_channels[i+1], bias=bias, activation=activations))\n",
    "\n",
    "    def forward(self, x, return_embed=False):\n",
    "        x = x.float()\n",
    "        embed = self.enc(x)\n",
    "        out = self.dec(embed)\n",
    "\n",
    "        if return_embed: return embed, out\n",
    "        return out\n",
    "\n",
    "class GroupedModel(nn.Module):\n",
    "    def __init__(self, n_clusters, model_class, **kwargs):\n",
    "        super(GroupedModel, self).__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        self.AE = nn.ModuleList(model_class(**kwargs) for i in range(n_clusters))\n",
    "\n",
    "    def _return_embed(self, embed, out, flag):\n",
    "        return (embed, out) if flag else out\n",
    "\n",
    "    def forward_with_clust(self, x, centers, clust, return_embed=False):\n",
    "        \"\"\" \n",
    "        To be used in the batched phase, computes output for input x, all belonging to the same cluster \n",
    "        \"\"\"\n",
    "        embed, out = self.AE[clust](x - centers[clust], True)\n",
    "\n",
    "        return self._return_embed(embed, out, return_embed)\n",
    "\n",
    "    def forward_with_centers(self, x, centers, return_embed=False):\n",
    "        \"\"\" \n",
    "        To be used in warmup phase, computes output for input x for all clusters. \n",
    "        Output format (batch, n_clusters, <data shape>)\n",
    "        \"\"\"\n",
    "        embed, out = self.AE[0](x - centers[0].reshape(x.shape[1:]), True)\n",
    "        embed, out = embed.reshape((len(x),1)+embed.shape[1:]), out.reshape((len(x),1)+out.shape[1:])\n",
    "\n",
    "        for n in range(1, self.n_clusters):\n",
    "            e, o = self.AE[n](x - centers[n].reshape(x.shape[1:]), True)\n",
    "            embed = torch.cat((embed, e.reshape((len(x),1)+e.shape[1:])), dim=1)\n",
    "            out = torch.cat((out, o.reshape((len(x),1)+o.shape[1:])), dim=1)\n",
    "\n",
    "        return self._return_embed(embed, out, return_embed)\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        raise NotImplementedError(\"Use one of `forward_with_centers` or `forward_with_clust`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: inputs of shape 5 (1d), AE follows 5->2->1->2->5 (1 = embed_dim)\n",
    "\n",
    "kwargs = {'enc_channels': (5,2,1),\n",
    "          'dec_channels': (1,2,5), \n",
    "          'bias': True, \n",
    "          'activations': nn.ReLU()}\n",
    "\n",
    "ae = Autoencoder(**kwargs)\n",
    "gae = GroupedModel(2, Autoencoder, **kwargs)\n",
    "\n",
    "dummy_input = torch.randn(64, 5)\n",
    "dummy_true = torch.randn(64,5) \n",
    "dummy_centers = torch.randn(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed  : torch.Size([64, 1])\n",
      "out    : torch.Size([64, 5])\n",
      "embed  : torch.Size([64, 2, 1])\n",
      "out    : torch.Size([64, 2, 5])\n",
      "embed  : torch.Size([64, 1])\n",
      "out    : torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "embed, out = ae(dummy_input, True)\n",
    "shapes(embed, out)\n",
    "\n",
    "embed, out = gae.forward_with_centers(dummy_input, dummy_centers, True)\n",
    "shapes(embed, out)\n",
    "\n",
    "embed, out = gae.forward_with_clust(dummy_input, dummy_centers, 0, True)\n",
    "shapes(embed, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_npy(x): \n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.detach().cpu().numpy()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import kmeans_plusplus\n",
    "\n",
    "class TensorizedAutoencoder(nn.Module):\n",
    "    def __init__(self, grouped_model, Y_data, regularizer_coef=0.01):\n",
    "        super(TensorizedAutoencoder, self).__init__()\n",
    "        self.n_clusters = grouped_model.n_clusters\n",
    "        self.centers = None\n",
    "        \n",
    "        self.autoencoders = grouped_model\n",
    "        self.reg = regularizer_coef\n",
    "\n",
    "        self.random_state = None    # set manually if needed, call model._init_clusters(Y) again\n",
    "        self._init_clusters(to_npy(Y_data))\n",
    "    \n",
    "    def mse(self, x, y, dim=None):\n",
    "        return F.mse_loss(x, y, reduction='none').mean(dim=dim) if dim is not None else F.mse_loss(x, y)\n",
    "\n",
    "    def _init_clusters(self, Y):\n",
    "        centers = kmeans_plusplus(Y.reshape(len(Y), -1), n_clusters=self.n_clusters, random_state=self.random_state)[0]\n",
    "        self.centers = torch.from_numpy(centers)\n",
    "        assert self.centers.shape == (self.n_clusters, Y.shape[1])\n",
    "    \n",
    "    def forward_with_clust(self, x, centers, clust, return_embed=False):\n",
    "        return self.autoencoders.forward_with_clust(x, centers, clust, return_embed)\n",
    "    \n",
    "    def forward_with_centers(self, x, centers, return_embed=False):\n",
    "        return self.autoencoders.forward_with_centers(x, centers, return_embed)\n",
    "    \n",
    "    def _assign_centers_to_data(self, data, one_hot=False, centers=None):\n",
    "        centers = centers or self.centers\n",
    "        centers = centers.reshape(self.n_clusters, -1)\n",
    "\n",
    "        assignments = torch.tensor([])\n",
    "        for i in range(self.n_clusters):\n",
    "            d = torch.norm(data.reshape(len(data), -1) - self.centers[i], dim=1).reshape(-1,1)\n",
    "            assignments = torch.cat((assignments,d), dim=1)\n",
    "        if one_hot: return F.one_hot(assignments.argmin(dim=1), self.n_clusters).T\n",
    "        return assignments.argmin(dim=1)\n",
    "\n",
    "    def _update_centers(self, Y, clust_assign):\n",
    "        assert clust_assign.shape == (self.n_clusters, len(Y)), \"check if clust_assign is in one-hot format\"\n",
    "        clust_assign.to(Y.device)\n",
    "        new_centers = clust_assign.float() @ Y.reshape(len(Y), -1).float()\n",
    "        new_norm = torch.sum(clust_assign, axis=1, dtype=torch.float).reshape(-1, 1) @ \\\n",
    "                        torch.ones(1, self.centers.shape[1], dtype=torch.float)\n",
    "        new_centers = new_centers / new_norm\n",
    "        return new_centers\n",
    "    \n",
    "    def compute_loss_warmup(self, x, y, clust_assign):\n",
    "        clusts = clust_assign.argmax(dim=0)\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x_, y_ = x.clone(), y.clone()\n",
    "\n",
    "        embed, out = self.autoencoders.forward_with_centers(x_, self.centers, True)\n",
    "        # (batch, n_clusters, <data shape>)\n",
    "\n",
    "        new_assignment = torch.zeros(self.n_clusters, batch_size)\n",
    "        loss = 0\n",
    "        for samp in range(batch_size):\n",
    "            true, e, o = y_[samp][None,:].repeat_interleave(self.n_clusters, dim=0), embed[samp], out[samp]\n",
    "            # shapes(true, e, o)\n",
    "\n",
    "            e_, o_ = e.reshape(self.n_clusters, -1), o.reshape(self.n_clusters, -1)\n",
    "\n",
    "            loss_proxy = self.mse(o_, true, dim=1) + self.reg * (torch.norm(e_, dim=1) ** 2)\n",
    "            # shapes(loss_proxy)\n",
    "\n",
    "            new_center = loss_proxy.argmin(dim=0)\n",
    "            loss += self.mse(o_[new_center], true[0]) + self.reg * (torch.norm(e_) ** 2)\n",
    "\n",
    "            new_assignment[:,samp][new_center] = 1\n",
    "\n",
    "        return loss, new_assignment\n",
    "\n",
    "    # def compute_loss_batch(self, x, y, ):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: inputs of shape 5 (1d)\n",
    "\n",
    "\n",
    "tae = TensorizedAutoencoder(gae, dummy_true)\n",
    "clust_assign = tae._assign_centers_to_data(dummy_true, one_hot=True)\n",
    "# clust_assign = F.one_hot(clusts, tae.n_clusters).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, new_assignment = tae.compute_loss_warmup(dummy_input[10:16], dummy_true[10:16], clust_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# make_dot(loss).render(\"attached\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
